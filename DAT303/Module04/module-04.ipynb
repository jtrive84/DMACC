{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAT303 - Spring 2024 - Module 4 Notebook\n",
    "---\n",
    "Name:    \n",
    "Date:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction to Machine Learning\n",
    "\n",
    "Machine learning empowers computers to learn and adapt from experience without being explicitly programmed. At its core, machine learning enables systems to automatically improve performance on specific tasks through exposure to data. This capability has led to groundbreaking applications across various sectors including healthcare, finance, insurance to name a few.\n",
    "\n",
    "In technical parlance, Machine Learning is a subset of AI, as illustrated below:\n",
    "\n",
    "![ml-ai](https://miro.medium.com/v2/resize:fit:631/0*Q3PICBlib-932hhH.png)\n",
    "\n",
    "Deep learning is a subset of machine learning that involves the use of neural networks with many layers — hence the term \"deep.\" These deep neural networks are designed to learn hierarchical representations of data, enabling the machine to make sense of complex, high-dimensional data sets through a process that mimics the way humans think and learn.\n",
    "\n",
    "\n",
    "Machine learning algorithms use statistical techniques to give computers the ability to \"learn\" with data. The learning process involves identifying patterns in data and making decisions with minimal human intervention. This differs from traditional computer programming, in which rules and data are used to obtain answers: In a Machine Learning context, answers (labels) and data are used to arrive at rules (in a supervised setting):\n",
    "\n",
    "![ml-vs-prog](https://datalya.com/blog/content/4-machine-learning/11-machine-learning-vs-traditional-programming-paradigm/ml_vs_traditional_paradigm.png)\n",
    "\n",
    "\n",
    "\n",
    "Depending on the nature of the task and data, machine learning can be categorized into five types:\n",
    "\n",
    "\n",
    "**Supervised Learning**: In a supervised setting, the algorithm learns from a labeled dataset, which means each example in the training dataset is paired with the correct output. The algorithm makes predictions or decisions based on input data and is corrected when its predictions are inaccurate. Over time, the algorithm adjusts its operations to improve accuracy. Applications include spam and fraud detection, sentiment analysis, and stock price prediction.\n",
    "\n",
    "\n",
    "**Unsupervised Learning:** Unsupervised learning deals with datasets without labeled responses. The goal is to discover inherent patterns or structures within the data without using labels, and instead aims to find patterns in the underlying data itself. Common unsupervised learning tasks include clustering, where the algorithm groups similar data points together, and dimensionality reduction, where the algorithm reduces the number of variables under consideration.\n",
    "\n",
    "\n",
    "**Semi-Supervised Learning**: Semi-supervised learning occupies a unique position in the machine learning spectrum, falling between supervised and unsupervised learning. This approach leverages a small amount of labeled data alongside a larger pool of unlabeled data to build more effective and comprehensive models. The motivation behind semi-supervised learning is practical: labeled data can be expensive or time-consuming to obtain, while unlabeled data is often abundant and underutilized. This is a particularly effective approach in computer vision related tasks. \n",
    "\n",
    "\n",
    "**Self-Supervised Learning** Self-supervised learning is an innovative approach in the realm of machine learning that enables algorithms to learn representations from data without the need for external annotations or labels. This technique falls under the broader umbrella of unsupervised learning but distinguishes itself by generating its own supervision from the input data. Essentially, self-supervised learning creates a pretext task from the data itself to predict any part of the data from other parts, thus learning valuable features that can be useful for a wide range of downstream tasks.\n",
    "\n",
    "\n",
    "**Reinforcement Learning**: Reinforcement learning involves an agent that learns to make decisions by performing certain actions and assessing the outcomes. It's akin to learning by trial and error, where the focus is on maximizing a reward signal. This type is widely used in gaming, navigation, and robotics.\n",
    "\n",
    "In this course, we will focus exclusively on the first two types: supervised and unsupervised learning. \n",
    "\n",
    "\n",
    "### Classification vs. Regression\n",
    "\n",
    "Within the supervised learning domain, we can further identify a problem as either a regression or classification task. **Regression** is concerned with predicting a continuous outcome variable based on one or more predictor variables. The goal is to establish a relationship between the predictors and the target variable, usually in the form of a linear equation for simple linear regression or a more complex model for non-linear regression. The performance of regression models is evaluated using different metrics such as RMSE/MAE or R-squared. The continuous outcome means that the prediction can take any value within a range, such as temperatures, prices, or distances. A few examples of problems that can be solved using regression:\n",
    "\n",
    "- Predicting the price of a home (dependent variable), given the zip code, square footage and number of bedrooms (independent variables). \n",
    "- In healthcare, predicting patient recovery times (dependent variable) based on variables like age, weight, genetics, and lifestyle factors (independent variables). \n",
    "- Forecasting energy demand and consumption in households (dependent variable), based on factors like temperature, time of year, economic activity, and population growth (independent variables). \n",
    "\n",
    "\n",
    "**Classification** deals with predicting categorical outcomes. The target variable in classification is discrete and represents different categories or classes into which the data points are grouped. For instance, a classification algorithm might be used to determine whether an email is spam or not (binary classification) or to identify the type of animal in an image from multiple categories (multi-class classification). Unlike regression, where the focus is on predicting a continuous quantity, classification aims at assigning class labels to instances based on the input features. During the training phase, the model learns the boundaries between different classes in the feature space, which it then uses to classify new instances. The performance of classification models is evaluated using different metrics such as accuracy, precision, recall, and the F1 score, which provide insights into the model’s ability to correctly discern between classes.\n",
    "In this course, we will focus primarily on binary classification, in which the outcome falls in one of two classes (yes/no, 1/0, ...). Some examples of classification tasks include:\n",
    "\n",
    "- Email spam detection: The classifier categorizes each email in a dataset as either spam (unwanted emails) or not spam. Machine learning models analyze the content and metadata of emails (e.g., sender, subject line, frequency of certain words) to learn patterns associated with spam and legitimate emails, helping to filter out unwanted messages automatically.\n",
    "\n",
    "- Medical Diagnosis: Classification algorithms are used in healthcare to diagnose diseases by analyzing patient data, including symptoms, genetic information, and medical images. For example, a model might classify patient cases as positive or negative for specific conditions (diabetes, cancer, etc.) or categorize tumors in medical images as benign or malignant, aiding in early detection and treatment planning.\n",
    "\n",
    "- Image Classification: Deep learning models, particularly convolutional neural networks (CNNs), are adept at categorizing images into various classes (e.g., identifying objects, animals, or scenes in photographs). This technology underpins image search engines, photo tagging features in social media, and automated quality control in manufacturing. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The core difference between regression and classification lies in the type of variable they aim to predict. Regression predicts continuous variables, while classification predicts discrete class labels. This fundamental distinction influences not only the choice of algorithms but also the evaluation metrics and methodologies applied in model training and validation.\n",
    "\n",
    "Moreover, the nature of the prediction output leads to different considerations in model development and application. Regression models must account for the range and distribution of continuous data, often requiring transformations or assumptions about the data distribution. Classification models, conversely, focus on categorizing instances and must manage challenges like class imbalance in which some classes are underrepresented in the training data.\n",
    "\n",
    "\n",
    "While regression and classification both play pivotal roles in supervised learning, their distinct approaches to prediction—quantitative versus qualitative—determine their applicability and effectiveness across different domains and problems. Understanding these differences is crucial for selecting the appropriate machine learning strategy, designing effective models and driving valuable insights from data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Key Concepts and Techniques\n",
    "\n",
    "Machine learning is built on a foundation of mathematics and statistics, with key concepts including probability, statistical inference, linear algebra and optimization. Some of the most popular machine learning techniques that we will cover include:\n",
    "\n",
    "- Linear Models: Linear models are characterized by their simplicity, interpretability and wide applicability across various types of data and prediction tasks. The essence of a linear model is to make predictions based on a linear combination of input features. These models assume that there is a linear relationship between the inputs (independent variables) and the output (dependent variable), making them particularly well-suited for problems where this linear approximation provides a good representation of the underlying data structure. Linear models are used for both classification and regression tasks.\n",
    "\n",
    "- Decision Trees: A model that uses a tree-like graph of decisions and their possible consequences. It's simple to understand and interpret and is used for classification and regression tasks.\n",
    "\n",
    "Neural Networks: Inspired by the structure and function of the human brain, neural networks consist of layers of interconnected nodes. Deep learning, a subset of machine learning, involves neural networks with many layers. These models have been highly successful in complex tasks such as image recognition, natural language processing, and autonomous driving.\n",
    "\n",
    "Support Vector Machines (SVM): A powerful classification method that works by finding the hyperplane that best divides a dataset into classes.\n",
    "\n",
    "K-Means Clustering: An unsupervised learning algorithm that groups data into a predefined number of clusters based on similarity metrics.\n",
    "\n",
    "Challenges and Ethical Considerations\n",
    "Despite its potential, machine learning presents challenges, including data privacy, security, bias, and fairness. Algorithms can inadvertently perpetuate or amplify biases present in the training data, leading to unfair or unethical outcomes. Addressing these challenges requires careful consideration of ethical implications and the development of robust, transparent models.\n",
    "\n",
    "The Future of Machine Learning\n",
    "Machine learning is an ever-evolving field, with research pushing the boundaries of what's possible. Advances in algorithmic efficiency, data processing, and computational power continue to unlock new applications. As the technology matures, it's expected to become even more integrated into daily life, revolutionizing industries and enhancing our understanding of the world.\n",
    "\n",
    "In conclusion, machine learning represents a significant leap forward in the way computers can assist in decision-making and pattern recognition. Its impact on society is profound, offering the potential to solve complex problems, enhance productivity, and drive innovation. As we continue to explore and refine these technologies, the future of machine learning promises even greater possibilities, making it a fascinating and crucial area of study and application.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Key Terms:\n",
    "\n",
    "Independent Variablwe\n",
    "Dependent Variable (target, response, output, outcome)\n",
    "Features, predictors, factors\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ml-vs-prog](https://datalya.com/blog/content/4-machine-learning/11-machine-learning-vs-traditional-programming-paradigm/ml_vs_traditional_paradigm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Getting Familiar with Pandas\n",
    "\n",
    "For this assignment, you will get familiar with Pandas by working with an auto insurance claims dataset. You will load the dataset from GitHub and complete the empty cells below. Your code should replace the `# YOUR CODE HERE #` comments in each cell. Some questions ask for written responses. These are markdown cells, and will be populated with `YOUR WRITTEN RESPONSE HERE`. Please remove these lines after entering your answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The DataFrame is loaded into the variable `df`. Display the first 10 rows of `df` using the DataFrame `head` method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "data_url = \"https://gist.githubusercontent.com/jtrive84/a765e9fa4f13c520fb89f0a65092fa51/raw/a639aaaab358ca2e6f4a69d3455933df4dc4d363/UKClaims.tsv\"\n",
    "\n",
    "df = pd.read_csv(data_url, sep=\"\\t\")\n",
    "\n",
    "\n",
    "#####  YOUR CODE HERE #####\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame consists of 4 columns:\n",
    "\n",
    "- **AGE**: The age group of the drivers in question.\n",
    "- **MODEL**: The insured vehicle model.\n",
    "- **AUTO_AGE**: The age group of the insured vehicle. \n",
    "- **LOSS**: The average loss amount for a given AGE, MODEL and AUTO_AGE. \n",
    "\n",
    "For example, drivers between the age of 17-20 years old (`AGE = 17-20`), having vehicle model A (`MODEL = A`) in which the vehicle is between 0 and 3 years old (`AUTO_AGE = 0 -3`), the average loss amount is $289 (`LOSS = 289.0`). This means that when a 17-20 year-old driving a model A vehicle that is less than 3 years old gets into an accident, on average it costs $289 to cover the repairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "2. Print the number of rows and columns in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Call the DataFrame `info()` method to get information about the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Print the datatypes of each column in the DataFrame using `dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Count the number of missing values in `df` for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Replace any missing values in the LOSS column with 0, then re-check the number of nulls in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Get a count of each of the groups in the AGE, MODEL and AUTO_AGE columns (Hint: use `value_counts()`). Print the results of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Return the Numpy representation of the LOSS column. Divide each element of the array by the maximum value, then print the array. (Hint: Do not use any looping: rely on Numpy's broadcasting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "9. Create a new DataFrame `df200` that contains only those rows with LOSS value greater than 200. How many rows are in this subset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Within `df200`, how many of the records are associated with `AGE = 40-49`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Within `df200`, how many of the records are associated with `MODEL = D`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Within `df200`, are there more rows associated with `AUTO_AGE = 4-7` or `AUTO_AGE = 8-9`? Put your code in the cell below, and your written response in the empty markdown cell after it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOUR WRITTEN RESPONSE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. What is the maximum LOSS for `MODEL = B` within `df200`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "14. What is the minimum LOSS for `MODEL = C` within `df200`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "15. What is the average LOSS for `MODEL = A` within `df200`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "16. Create a new column `MEAN_DIFF` that subtracts the average LOSS amount in `df` from the LOSS column. How many rows have MEAN_DIFF less than 0? How many rows have MEAN_DIFF greater than 0? Write your code in the next cell, and your written response in the following empty markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOUR WRITTEN RESPONSE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Group-wise Analysis\n",
    "\n",
    "\n",
    "> The problems that follow require knowledge of `groupby` in Pandas. Be sure to review \n",
    "[Pandas Group by: Split-Apply-Combine](https://dmacc.instructure.com/courses/11337/pages/activities-for-module-2/edit), also listed in Canvas under *Activities for Module 2*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Compute the average loss amount by AGE. Inspect the resulting DataFrame. Which AGE group has the highest average LOSS? The lowest? Write your code in the next cell, and your written response in the following empty markdown cell with the minimum and maximum average LOSS amounts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOUR WRITTEN RESPONSE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Compute the average loss amount by MODEL. Inspect the resulting DataFrame. Which MODEL has the highest average LOSS? The lowest? Write your code in the next cell, and your written response in the following empty markdown cell with the minimum and maximum average LOSS and associated MODEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOUR WRITTEN RESPONSE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Consider only those rows in which `AUTO_AGE = 10+`. How do the highest and lowest LOSS amounts differ from the results from problem 16? Specifically, are the MODELs with the highest/lowest average LOSS the same when only considering vehicles with `AUTO_AGE = 10+`?. Write your code in the next cell, and your written response in the following empty markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOUR WRITTEN RESPONSE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. What are some shortcomings of this data? Name at least two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III. Matplotlib\n",
    "\n",
    "Matplotlib is a comprehensive plotting library for Python widely used in scientific computing and data visualization. It provides a versatile framework for creating high-quality static, interactive, and animated visualizations. Matplotlib has become a cornerstone tool for researchers, engineers, data scientists, and analysts due to its flexibility and ease of use.\n",
    "\n",
    "At its core, Matplotlib offers a vast array of plotting functions to create a wide range of plots, including line plots, scatter plots, bar charts, histograms, pie charts, and more. Users can customize every aspect of their plots, from colors and line styles to labels and annotations, allowing for precise control over the appearance of visualizations.\n",
    "\n",
    "Matplotlib seamlessly integrates with other Python libraries such as NumPy and pandas, making it an essential component of the data science ecosystem. Its compatibility with various GUI toolkits enables the creation of interactive plots for exploring data dynamically.\n",
    "\n",
    "It is assumed that you have some familiarity with Matplotlib. The following problems should be a refresher. We will be using Matplotlib for more sophisticated visualizations in later modules. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Generate 10,000 random samples from a standard normal distribution and plot a red histogram with 18 bins. \n",
    "\n",
    "> Hint: refer to [this](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html) link for information on drawing standard normal samples in Numpy. By *standard normal*, we mean a normal distribution with mean = 0 and variance = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####  YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Using the two datasets below, plot `y1` and a scatterplot and `y2` and a lineplot. Each should use `x` as the independent variable. Scatterpoints should be **blue** and the lineplot should be a **red** dashed line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "rng = np.random.default_rng(516)\n",
    "\n",
    "x = np.linspace(0, 10, 25)\n",
    "y1 = 3 * rng.normal(loc=x, scale=1.50) + 7\n",
    "A = np.vstack([np.ones(len(x)), x]).T\n",
    "b, m = np.linalg.lstsq(A, y1 ,rcond=None)[0]\n",
    "y2 = m * x + b\n",
    "\n",
    "\n",
    "#####  YOUR CODE HERE #####\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAT303 - Spring 2024 - Module 5.1 Notebook\n",
    "---\n",
    "Name:    \n",
    "Date:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Metrics \n",
    "\n",
    "Metrics in machine learning regression are used to evaluate the performance of regression models. They provide quantifiable measures that help assess how well the model is able to predict the target variable. Regression metrics are used for:\n",
    "\n",
    "- **Model Comparison**: Metrics allow you to compare different regression models to determine which one performs better on a given dataset. By comparing metrics like MAE, MSE, RMSE, etc., you can choose the model that best suits your specific problem and requirements.\n",
    "\n",
    "- **Model Selection**: Metrics help in selecting the best model architecture or hyperparameters during the model training process. For example, you might use cross-validation with different hyperparameters and choose the model with the lowest MSE.\n",
    "\n",
    "- **Performance Monitoring**: Once a model is deployed, metrics are used to monitor its performance over time. By tracking metrics regularly, you can identify when the model's performance degrades or when recalibration is necessary.\n",
    "\n",
    "- **Insights into Model Behavior**: Metrics provide insights into how the model is performing across different parts of the data distribution. For example, understanding if the model performs better on certain subsets of the data can help identify biases or areas for improvement.\n",
    "\n",
    "\n",
    "In this notebook, we focus on three regression metrics: $R^2$, Mean Squared Error (MSE) and Mean Absolute Error (MAE). You will read about each metric, then implement each yourself in a function to ensure you understand how they are computed. Finally, you will call the appropriate scikit-learn function to verify that your from-scratch functions match the output from the scikit-learn utilities. \n",
    "\n",
    "\n",
    "\n",
    "### $R^2$ (Coefficient of Determination)\n",
    "\n",
    "The expression representing the coefficient of determination is given by\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2},\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $y_{i}$ represents the $i^{th}$ observation.\n",
    "- $\\bar{y}$ represents the mean over actuals.\n",
    "- $\\hat{y}_i$ represents the $i^{th}$ model output. \n",
    "- $n$ represents the number of samples in the dataset.\n",
    "\n",
    "\n",
    "$R^2$ is used to evaluate the performance of regression models. It provides a measure of how well the independent variables (features) explain the variability of the dependent variable (target). $R^2$ ranges from 0 to 1, where 0 indicates that the model does not explain any of the variability of the target variable around its mean and 1 indicates that the model perfectly explains all the variability of the target variable around its mean. $R^2$ can also be negative, which indicates that the model is worse than a simple horizontal line (in the univariate case). It's important to note that \n",
    "$R^2$ should be interpreted alongside other metrics to gain a comprehensive understanding of the model's performance.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### MSE (Mean Squared Error)\n",
    "\n",
    "The expression representing MSE is given by\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2,\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $y_{i}$ represents the $i^{th}$ observation.\n",
    "- $\\hat{y}_i$ represents the $i^{th}$ model output. \n",
    "- $n$ represents the number of samples in the dataset.\n",
    "\n",
    "MSE is one of the most common metrics used to evaluate the performance of regression models. MSE quantifies the average squared difference between the actual values (or ground truth) and the predicted values produced by the regression model. It penalizes larger errors more heavily than smaller ones due to squaring the differences. A smaller MSE value indicates that the model's predictions are closer to the actual values, suggesting a better fit of the regression model to the data.\n",
    "However, MSE is sensitive to outliers in the data. Large errors from outliers can significantly inflate the MSE, making it less robust to extreme values.   \n",
    "\n",
    "When comparing different regression models, the one with the lowest MSE is generally preferred as it indicates better predictive performance on average.\n",
    "\n",
    "<br>\n",
    "\n",
    "### MAE (Mean Absolute Error)\n",
    "\n",
    "The expression representing MAE is given by\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y}_i \\right|, \n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $y_{i}$ represents the $i^{th}$ observation.\n",
    "- $\\hat{y}_i$ represents the $i^{th}$ model output. \n",
    "- $n$ represents the number of samples in the dataset.\n",
    "\n",
    "\n",
    "MAE is also used to evaluate the performance of regression models. MAE measures the average absolute difference between the actual values and the predicted values produced by the regression model. It gives equal weight to all errors regardless of their magnitude, making it less sensitive to outliers compared to metrics like Mean Squared Error (MSE). A smaller MAE value indicates that the model's predictions are closer to the actual values, suggesting a better fit of the regression model to the data. MAE is easy to interpret as it represents the average magnitude of errors. For example, an MAE of 2 means that, on average, the model's predictions are off by 2 units from the actual values. MAE is preferred in situations where outliers are present in the data and you want the evaluation to be less influenced by these extreme values.   \n",
    "\n",
    "When comparing different regression models, the one with the lowest MAE is generally preferred as it indicates better predictive performance on average.\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Complete questions 1-8. Use the synthetically generated `yact` (target) and `ypred` (modeled output) below for each metric evaluation. Do not use for loops in your metric functions: Take advantage of Numpy's broadcasting. \n",
    "\n",
    "\n",
    "Follow the instructions in each cell. For questions 4-6, more information on scikit-learn metrics can be found [here](https://scikit-learn.org/stable/modules/classes.html#regression-metrics).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate samples for metric evaluation.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(516)\n",
    "\n",
    "x = np.linspace(0, 100, 250)\n",
    "yact = 12 * rng.normal(loc=x, scale=45.68) + 4.25\n",
    "A = np.vstack([np.ones(len(x)), x]).T\n",
    "b, m = np.linalg.lstsq(A, yact ,rcond=None)[0]\n",
    "ypred = m * x + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement a function named `my_rsqrd`. It should accept `yact` and `ypred` as arguments and return a single scalar value representing the coefficient of determination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Implement a function named `my_mse`. It should accept `yact` and `ypred` as arguments and return a single scalar value representing the mean squared error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement a function named `my_mae`. It should accept `yact` and `ypred` as arguments and return a single scalar value representing the mean absolute error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implement a function named `sklearn_rsqrd`. It should accept `yact` and `ypred`, and return the value from the `r2_score` function in scikit-learn (should only require 1-2 lines of code including the return statement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Implement a function named `sklearn_mse`. It should accept `yact` and `ypred`, and return the value from the `mean_squared_error` function in scikit-learn (should only require 1-2 lines of code including the return statement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Implement a function named `sklearn_mae`. It should accept `yact` and `ypred`, and return the value from the `mean_absolute_error` function in scikit-learn (should only require 1-2 lines of code including the return statement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Run the next cell to ensure outputs match for each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tol = 1e-5\n",
    "\n",
    "rsqrd1 = my_rsqrd(yact, ypred)\n",
    "rsqrd2 = sklearn_rsqrd(yact, ypred)\n",
    "\n",
    "mse1 = my_mse(yact, ypred)\n",
    "mse2 = sklearn_mse(yact, ypred)\n",
    "\n",
    "mae1 = my_mae(yact, ypred)\n",
    "mae2 = sklearn_mae(yact, ypred)\n",
    "\n",
    "\n",
    "if abs(rsqrd1 - rsqrd2) <= tol:\n",
    "    print(f\"+ Outputs match for my_rsqrd vs. sklearn_rsqrd ({rsqrd1:.5f} vs. {rsqrd2:.5f}) [OK]\")\n",
    "else:\n",
    "    print(f\"- Outputs do not match for my_rsqrd vs. sklearn_rsqrd ({rsqrd1:.5f} vs. {rsqrd2:.5f}) [Not OK]\")\n",
    "\n",
    "if abs(mse1- mse2) <= tol:\n",
    "    print(f\"+ Outputs match for my_mse vs. sklearn_mse ({mse1:.5f} vs. {mse2:.5f}) [OK]\")\n",
    "else:\n",
    "    print(f\"- Outputs do not match for my_mse vs. sklearn_mse ({mse1:.5f} vs. {mse2:.5f}) [Not OK]\")\n",
    "\n",
    "if abs(mae1- mae2) <= tol:\n",
    "    print(f\"+ Outputs match for my_mae vs. sklearn_mae ({mae1:.5f} vs. {mae2:.5f})  [OK]\")\n",
    "else:\n",
    "    print(f\"- Outputs do not match for my_mae vs. sklearn_mae ({mae1:.5f} vs. {mae2:.5f}) [Not OK]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Pick one regression metric not covered in this exercise (full list [here](https://scikit-learn.org/stable/modules/classes.html#regression-metrics)), and briefly describe a situation or modeling context in which this new metric might be preferrable to $R^2$, MSE or MAE. No more than 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN RESPONSE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

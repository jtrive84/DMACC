{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Data Pre-Processing in scikit-learn\n",
    "---\n",
    "Author: James D. Triveri\n",
    "\n",
    "\n",
    "In scikit-learn, data preprocessing refers to the preparation and transformation of raw data into a format that is suitable for machine learning algorithms. This process typically involves several steps, including:\n",
    "\n",
    "- Handling missing values, outliers, or other inconsistencies in the dataset. Scikit-learn provides tools for imputation of missing values.\n",
    "\n",
    "- Scaling numerical features to ensure that they have similar scales. This is important for many machine learning algorithms, particularly those based on distance calculations or gradient descent optimization. Scikit-learn offers various scaling methods such as standardization (StandardScaler) and min-max scaling (MinMaxScaler).\n",
    "\n",
    "- Converting categorical features into a numerical format suitable for machine learning algorithms. This may involve techniques such as one-hot encoding (`OneHotEncoder`) or label encoding (`LabelEncoder`).\n",
    "\n",
    "\n",
    "\n",
    "## Creating Train-Test Splits\n",
    "\n",
    "The primary purpose of splitting data into train and test sets is to evaluate the performance of the model on unseen data. By training the model on a subset of the data (the training set) and then evaluating its performance on a separate subset (the test set), we can assess how well the model generalizes to new, unseen data. This helps us understand whether the model has learned meaningful patterns from the data or if it\"s simply memorizing the training examples, which is the definition of overfitting. Overfitting occurs when a model learns to perform well on the training data but fails to generalize to new data. By evaluating the model on a separate test set, we can detect overfitting. If the model performs significantly worse on the test set compared to the training set, it indicates that the model has overfit the training data, and adjustments may be needed to improve its generalization ability.\n",
    "\n",
    "In addition, machine learning models often have hyperparameters that need to be tuned for optimal performance. Splitting the data allows us to perform hyperparameter tuning on the training set while keeping the test set untouched. This helps prevent \"leakage\" of information from the test set into the model training process, which could lead to overly optimistic performance estimates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Small Ames Housing Dataset for a Regression Task\n",
    "\n",
    "The Small Ames Housing Dataset consists of 2,930 records, each of which represent homes sales in Ames. \n",
    "The target variable is `sale_price`. The goal would be to create a model to predict `sale_price` using \n",
    "the other columns in the dataset. \n",
    "\n",
    "We read the data into a Pandas DataFrame and display the first few records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lot_area</th>\n",
       "      <th>bld_type</th>\n",
       "      <th>house_style</th>\n",
       "      <th>exterior</th>\n",
       "      <th>foundation</th>\n",
       "      <th>basement_sqft</th>\n",
       "      <th>central_air</th>\n",
       "      <th>first_floor_sqft</th>\n",
       "      <th>full_bath</th>\n",
       "      <th>kitchen_score</th>\n",
       "      <th>fireplaces</th>\n",
       "      <th>garage_type</th>\n",
       "      <th>garage_nbr_cars</th>\n",
       "      <th>paved_drive</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31770</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1656</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>2</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2</td>\n",
       "      <td>P</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11622</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>882.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14267</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1329</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11160</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>2110</td>\n",
       "      <td>2</td>\n",
       "      <td>Ex</td>\n",
       "      <td>2</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13830</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>PConc</td>\n",
       "      <td>928.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>928</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>1</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lot_area bld_type house_style exterior foundation  basement_sqft  \\\n",
       "0     31770     1Fam      1Story  BrkFace     CBlock         1080.0   \n",
       "1     11622     1Fam      1Story  VinylSd     CBlock          882.0   \n",
       "2     14267     1Fam      1Story  Wd Sdng     CBlock         1329.0   \n",
       "3     11160     1Fam      1Story  BrkFace     CBlock         2110.0   \n",
       "4     13830     1Fam      2Story  VinylSd      PConc          928.0   \n",
       "\n",
       "  central_air  first_floor_sqft  full_bath kitchen_score  fireplaces  \\\n",
       "0           Y              1656          1            TA           2   \n",
       "1           Y               896          1            TA           0   \n",
       "2           Y              1329          1            Gd           0   \n",
       "3           Y              2110          2            Ex           2   \n",
       "4           Y               928          2            TA           1   \n",
       "\n",
       "  garage_type  garage_nbr_cars paved_drive  sale_price  \n",
       "0      Attchd                2           P      215000  \n",
       "1      Attchd                1           Y      105000  \n",
       "2      Attchd                1           Y      172000  \n",
       "3      Attchd                2           Y      244000  \n",
       "4      Attchd                2           Y      189900  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://gist.githubusercontent.com/jtrive84/9b96df3f5b23ef1cef68c6bbe5983153/raw/588858f552167732de4d2440505eab54d8d80316/ames-housing-small.csv\",\n",
    "    na_values=\"\"\n",
    "    )\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The first step is to identify which columns represent continuous features and which represent categorical features. Categorical features are usually strings (or objects), but can also be integer-valued (for example, `fireplaces` should be treated as a categorical feature, not a continuous feature, since the column only takes on 5 distinct values). \n",
    "\n",
    "Note also that categorical features can be one of two types:\n",
    "\n",
    "- **Nominal features** are categorical variables where the categories do not have a natural ordering or hierarchy (\"bird\", \"cat\", \"dog\").\n",
    "\n",
    "- **Ordinal features** are categorical variables where the categories have a natural order or hierarchy (\"low\", \"medium\", \"high\"), or \"fireplaces\" from our dataset. \n",
    "\n",
    "We can print the data types of each column in the DataFrame to give us an idea of which features are continuous and which are categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lot_area              int64\n",
       "bld_type             object\n",
       "house_style          object\n",
       "exterior             object\n",
       "foundation           object\n",
       "basement_sqft       float64\n",
       "central_air          object\n",
       "first_floor_sqft      int64\n",
       "full_bath             int64\n",
       "kitchen_score        object\n",
       "fireplaces            int64\n",
       "garage_type          object\n",
       "garage_nbr_cars       int64\n",
       "paved_drive          object\n",
       "sale_price            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We treat `lot_area`, `first_floor_sqft` and `basement_sqft` as continuous features. All other columns will be considered categorical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = \"sale_price\"\n",
    "\n",
    "continuous = [\n",
    "    \"lot_area\", \"first_floor_sqft\", \"basement_sqft\"\n",
    "    ]\n",
    "\n",
    "categorical = [\n",
    "    \"bld_type\", \"house_style\", \"exterior\", \"foundation\", \"central_air\", \n",
    "    \"full_bath\", \"kitchen_score\", \"fireplaces\", \"garage_type\", \"garage_nbr_cars\", \n",
    "    \"paved_drive\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn has good support for imputing continuous features, but for categorical features we will typically forgo imputation. Instead of imputing missing categorical values, we identify them as \"missing\", and treat those values as a category unto themselves. This will allow us to assess whether these missing values have any association with the target variable as a group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set any missing categorical features to \"missing\".\n",
    "for feature in categorical:\n",
    "    df[feature] = df[feature].astype(\"str\").fillna(\"missing\")\n",
    "\n",
    "\n",
    "# Strip whitespace from object columns.\n",
    "df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in a position to create our preprocessing pipelines. We initialize a `ColumnTransformer` instance, which gives us the ability to define separate preprocessing steps for different groups of columns (in our case, categorical vs. continuous). \n",
    "\n",
    "Let's assume we intend to use the `LinearRegression` model in scikit-learn. As most models don't support categorical features, it is necessary to encode them using a numerical representation. We will [one-hot encode](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) our categorical features within our pre-processing pipeline. \n",
    "\n",
    "Note that some models can accept ordinal categorical features directly (for example, `GradientBoostingRegressor`), but for now we are assuming all categorical features will be one-hot encoded. \n",
    "\n",
    "We also impute missing continuous values using `KNNImputer`. This is preferable to `SimpleImputer` since it doesn't assume independence of features as `SimpleImputer` does. \n",
    "\n",
    "Finally, we standardize the continuous features to have mean 0 and standard deviation 1. This is not strictly necessary, but helps convergence for models that rely on gradient descent. It also makes model coefficients more easily interpretable. \n",
    "\n",
    "Here is how we would setup the pre-processing pipeline, starting with creating the train-validation-test split. We create three separate datasets, which requires calling `train_test_split` twice. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dftrain.shape: (1902, 48)\n",
      "dfvalid.shape: (666, 48)\n",
      "dftest.shape : (359, 48)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example pre-processing pipeline for Small Ames Housing Dataset.\n",
    "\"\"\"\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "# Create train-validation-test split.\n",
    "y = df[target]\n",
    "dftrain, dfvalid, ytrain, yvalid = train_test_split(df, y, test_size=.35, random_state=516)\n",
    "dfvalid, dftest, yvalid, ytest = train_test_split(dfvalid, yvalid, test_size=.35, random_state=516)\n",
    "\n",
    "\n",
    "# Continuous feature preprocessing  pipeline.\n",
    "continuous_transformer = make_pipeline(\n",
    "    KNNImputer(), \n",
    "    StandardScaler()\n",
    "    )\n",
    "\n",
    "# Categorical feature preprocessing pipeline.\n",
    "categorical_transformer = make_pipeline(\n",
    "    OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "    )\n",
    "\n",
    "# Combine categorical and continuous feature pipelines.\n",
    "transformer = ColumnTransformer(transformers=[\n",
    "    (\"continuous\" , continuous_transformer, continuous),  \n",
    "    (\"categorical\", categorical_transformer, categorical)\n",
    "    ], remainder=\"drop\", verbose_feature_names_out=False\n",
    "    ).set_output(transform=\"pandas\")\n",
    "\n",
    "\n",
    "# Call fit_transform on dftrain.\n",
    "dftrain = transformer.fit_transform(dftrain)\n",
    "\n",
    "\n",
    "# Only call transform on dfvalid and dftest. \n",
    "dfvalid = transformer.transform(dfvalid)\n",
    "dftest = transformer.transform(dftest)\n",
    "\n",
    "\n",
    "print(f\"dftrain.shape: {dftrain.shape}\")\n",
    "print(f\"dfvalid.shape: {dfvalid.shape}\")\n",
    "print(f\"dftest.shape : {dftest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we call `fit_transform` on the training set but only `transform` on the test set. This is to prevent leaking information from our test set into our training set. This is a common mistake that even experienced machine learning practitioners sometimes fall victim to. **Ensure `fit_transform` is only ever called on the training set, and that only `transform` is called on the test/validation set.**.\n",
    "\n",
    "We can inspect our training data and see that the specified preprocessing steps have been executed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lot_area</th>\n",
       "      <th>first_floor_sqft</th>\n",
       "      <th>basement_sqft</th>\n",
       "      <th>bld_type_2fmCon</th>\n",
       "      <th>bld_type_Duplex</th>\n",
       "      <th>bld_type_Twnhs</th>\n",
       "      <th>bld_type_TwnhsE</th>\n",
       "      <th>house_style_1.5Unf</th>\n",
       "      <th>house_style_1Story</th>\n",
       "      <th>house_style_2.5Fin</th>\n",
       "      <th>...</th>\n",
       "      <th>garage_type_BuiltIn</th>\n",
       "      <th>garage_type_CarPort</th>\n",
       "      <th>garage_type_Detchd</th>\n",
       "      <th>garage_type_nan</th>\n",
       "      <th>garage_nbr_cars_1</th>\n",
       "      <th>garage_nbr_cars_2</th>\n",
       "      <th>garage_nbr_cars_3</th>\n",
       "      <th>garage_nbr_cars_4</th>\n",
       "      <th>paved_drive_P</th>\n",
       "      <th>paved_drive_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>0.778125</td>\n",
       "      <td>-0.729801</td>\n",
       "      <td>-0.537453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0.328971</td>\n",
       "      <td>0.860988</td>\n",
       "      <td>1.026819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>-0.114787</td>\n",
       "      <td>-0.535428</td>\n",
       "      <td>-0.620512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>0.136705</td>\n",
       "      <td>-0.210620</td>\n",
       "      <td>-0.156767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>-0.606366</td>\n",
       "      <td>-0.893483</td>\n",
       "      <td>-0.555911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lot_area  first_floor_sqft  basement_sqft  bld_type_2fmCon  \\\n",
       "1509  0.778125         -0.729801      -0.537453              0.0   \n",
       "1439  0.328971          0.860988       1.026819              0.0   \n",
       "1285 -0.114787         -0.535428      -0.620512              0.0   \n",
       "1375  0.136705         -0.210620      -0.156767              0.0   \n",
       "1903 -0.606366         -0.893483      -0.555911              0.0   \n",
       "\n",
       "      bld_type_Duplex  bld_type_Twnhs  bld_type_TwnhsE  house_style_1.5Unf  \\\n",
       "1509              0.0             0.0              0.0                 0.0   \n",
       "1439              0.0             0.0              0.0                 0.0   \n",
       "1285              0.0             0.0              0.0                 0.0   \n",
       "1375              0.0             0.0              0.0                 0.0   \n",
       "1903              0.0             0.0              0.0                 0.0   \n",
       "\n",
       "      house_style_1Story  house_style_2.5Fin  ...  garage_type_BuiltIn  \\\n",
       "1509                 0.0                 0.0  ...                  0.0   \n",
       "1439                 1.0                 0.0  ...                  0.0   \n",
       "1285                 0.0                 0.0  ...                  0.0   \n",
       "1375                 0.0                 0.0  ...                  0.0   \n",
       "1903                 1.0                 0.0  ...                  0.0   \n",
       "\n",
       "      garage_type_CarPort  garage_type_Detchd  garage_type_nan  \\\n",
       "1509                  0.0                 0.0              0.0   \n",
       "1439                  0.0                 0.0              0.0   \n",
       "1285                  0.0                 1.0              0.0   \n",
       "1375                  0.0                 1.0              0.0   \n",
       "1903                  0.0                 1.0              0.0   \n",
       "\n",
       "      garage_nbr_cars_1  garage_nbr_cars_2  garage_nbr_cars_3  \\\n",
       "1509                1.0                0.0                0.0   \n",
       "1439                0.0                1.0                0.0   \n",
       "1285                0.0                1.0                0.0   \n",
       "1375                0.0                1.0                0.0   \n",
       "1903                1.0                0.0                0.0   \n",
       "\n",
       "      garage_nbr_cars_4  paved_drive_P  paved_drive_Y  \n",
       "1509                0.0            0.0            1.0  \n",
       "1439                0.0            0.0            1.0  \n",
       "1285                0.0            0.0            1.0  \n",
       "1375                0.0            0.0            1.0  \n",
       "1903                0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous feature names are prefixed with `continuous_` and categorical feature names with `categorical_`. Each categorical column will now consist only of 1s and 0s. Notice there are no longer string or object type columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lot_area               float64\n",
       "first_floor_sqft       float64\n",
       "basement_sqft          float64\n",
       "bld_type_2fmCon        float64\n",
       "bld_type_Duplex        float64\n",
       "bld_type_Twnhs         float64\n",
       "bld_type_TwnhsE        float64\n",
       "house_style_1.5Unf     float64\n",
       "house_style_1Story     float64\n",
       "house_style_2.5Fin     float64\n",
       "house_style_2.5Unf     float64\n",
       "house_style_2Story     float64\n",
       "house_style_SFoyer     float64\n",
       "house_style_SLvl       float64\n",
       "exterior_CemntBd       float64\n",
       "exterior_HdBoard       float64\n",
       "exterior_MetalSd       float64\n",
       "exterior_Plywood       float64\n",
       "exterior_VinylSd       float64\n",
       "exterior_Wd Sdng       float64\n",
       "exterior_WdShing       float64\n",
       "exterior_nan           float64\n",
       "foundation_CBlock      float64\n",
       "foundation_PConc       float64\n",
       "foundation_nan         float64\n",
       "central_air_Y          float64\n",
       "full_bath_1            float64\n",
       "full_bath_2            float64\n",
       "full_bath_3            float64\n",
       "full_bath_4            float64\n",
       "kitchen_score_Fa       float64\n",
       "kitchen_score_Gd       float64\n",
       "kitchen_score_TA       float64\n",
       "fireplaces_1           float64\n",
       "fireplaces_2           float64\n",
       "fireplaces_3           float64\n",
       "garage_type_Attchd     float64\n",
       "garage_type_Basment    float64\n",
       "garage_type_BuiltIn    float64\n",
       "garage_type_CarPort    float64\n",
       "garage_type_Detchd     float64\n",
       "garage_type_nan        float64\n",
       "garage_nbr_cars_1      float64\n",
       "garage_nbr_cars_2      float64\n",
       "garage_nbr_cars_3      float64\n",
       "garage_nbr_cars_4      float64\n",
       "paved_drive_P          float64\n",
       "paved_drive_Y          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dftrain.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, we are ready to use our data to fit a model. Let's use the `LinearRegression` model mentioned earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE     : 22,404.13.\n",
      "Validation MAE: 24,118.99.\n",
      "Test MAE      : 20,605.65.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit model on training set. \n",
    "mdl = lr.fit(dftrain, ytrain)\n",
    "\n",
    "# Training predictions. \n",
    "ypred_train = mdl.predict(dftrain)\n",
    "\n",
    "# Generate predictions on validation  set.\n",
    "ypred_valid = mdl.predict(dfvalid)\n",
    "\n",
    "# Assess model on final test set. The test set is typically used to compare \n",
    "# the output of many models to see how well they perform on unseen data.\n",
    "ypred_test = mdl.predict(dftest)\n",
    "\n",
    "\n",
    "# Compute mean absolute error.\n",
    "train_mae = mean_absolute_error(ytrain, ypred_train)\n",
    "valid_mae = mean_absolute_error(yvalid, ypred_valid)\n",
    "test_mae = mean_absolute_error(ytest, ypred_test)\n",
    "\n",
    "print(f\"Train MAE     : {train_mae:,.2f}.\")\n",
    "print(f\"Validation MAE: {valid_mae:,.2f}.\")\n",
    "print(f\"Test MAE      : {test_mae:,.2f}.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

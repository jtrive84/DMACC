{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAT303 - Spring 2024 - Module 5.2 Notebook\n",
    "---\n",
    "Name:    \n",
    "Date:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will fit a number of regression models and evaluate the results on the *nyc-sales-rolling.csv* dataset available on Canvas. There are three sub-sections to this assignment:\n",
    "\n",
    "- Part I: Data Preparation  \n",
    "- Part II: Fitting Regression Models\n",
    "- Part III: Evaluation  \n",
    "\n",
    "**BE SURE TO READ THE INSTRUCTIONS FOR ALL SECTIONS!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "## Part I: Data Preparation\n",
    "---\n",
    "\n",
    "You will first pre-process the dataset. You can use the example code provided [here](https://github.com/jtrive84/DMACC/blob/master/DAT303/Demos/preprocessing-pipeline-demo.ipynb) to give you an idea of how to handle imputation, scaling and one-hot encoding for categorical features. The objective is to implement a number of models to predict the log of SALE_PRICE using selected features. Some tasks you will need to handle include:\n",
    "\n",
    "- Determining which features are categorical and which are continuous.\n",
    "    - For example, `GROSS SQUARE FEET` is a continuous feature but in the dataset, since missing values are represented as `\"-\"`, it will be read into Pandas as a object (string) column. You may want to use the `na_values` argument from `pd.read_csv` to handle this at load time.\n",
    "\n",
    "    - Handling sparsely represented values in categorical features (see Part I #8).\n",
    "\n",
    "- Imputing missing values (remember that imputation is handled differently for continuous and categorical features).\n",
    "\n",
    "- Scaling continuous features.\n",
    "\n",
    "- One-hot encoding categorical features.\n",
    "\n",
    "- Pick which columns to ignore (for example, the models we are building are not time dependent, so you should exclude SALE_DATE).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1.a Read *nyc-rolling-sales.csv* into a Pandas DataFrame. \n",
    "- 1.b Drop any records in which SALE PRICE is NA or 0. \n",
    "- 1.c Create a new column named log_SALE_PRICE which represents the natual log of the original SALE PRICE column. This will be our target going forward. \n",
    "- 1.d Drop SALE PRICE and SALE DATE.\n",
    "- 1.e Display the first 5 rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "2. Create a bar plot of the median log_SALE_PRICE by BOROUGH. Ensure the values for BOROUGH on the x-axis are ordered correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "3. Which borough has the highest median log_SALE_PRICE? The lowest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOUR WRITTEN RESPONSE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "4. Plot a histogram of log_SALE_PRICE. Experiment with the number of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "5. Describe the distribution of the target variable in words (symmetric, skewed, etc.). Are outliers apparent? What tests are available in scikit-learn to detect outliers? Name two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "6. Replace 0 values in YEAR BUILT with NA so they will be properly inputed. Investigate whether any other columns should receive similar treatment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "7. Inspect the columns of the DataFrame, and create categorical and continuous feature lists. Be sure to remove any redundant columns (perhaps TOTAL UNITS should be excluded, since it is a perfect linear combination of COMMERCIAL UNITS and RESIDENTIAL UNITS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "8. For each feature identified as categorical, consolidate values into an \"OTHER\" group if they appear less than 100 times. For example, in BUILDING CLASS CATEGORY, \"CONDO WAREHOUSES/FACTORY/INDUS\" is present in the data only 10 times. This should be replaced with \"OTHER\". Replace all such values with \"OTHER\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "9. Implement the preprocessing pipeline. Be sure to create train, validation and test subsets. We will use train and validation sets for modeling, but the test set will not be used until Part III to compare all models on unseen data. Print the number of rows and columns in each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"dftrain.shape: {dftrain.shape}\")\n",
    "print(f\"dfvalid.shape: {dfvalid.shape}\")\n",
    "print(f\"dftest.shape : {dftest.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Part II: Fitting Regression Models\n",
    "---\n",
    "In this section, you will fit 4 separate regression models, and answer any additional questions about the given model. In parituclar, you will fit the following models:\n",
    "\n",
    "- [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso)\n",
    "- [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn-tree-decisiontreeregressor)\n",
    "- Regression model of your choice (list of models available [here](https://scikit-learn.org/stable/supervised_learning.html))\n",
    "\n",
    "Follow the instructions that accompany each model. Remember that in this section, **We are only working with the training and validation sets, not the test set!**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit a LinearRegression model. Report/print the following metrics to 5 decimal places:\n",
    "\n",
    "- Train $R^2$, MSE and MAE.\n",
    "- Validation $R^2$, MSE and MAE.\n",
    "\n",
    "Name the LinearRegression model you fit `mdl1`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "##### YOUR CODE HERE #####\n",
    "\n",
    "# Fit model on training set. \n",
    "\n",
    "\n",
    "# Generate predictions on test set.\n",
    "\n",
    "\n",
    "# Generate predictions on validation set.\n",
    "\n",
    "\n",
    "# Compute training metrics.\n",
    "\n",
    "\n",
    "# Compute validation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "2. Did each metric increase or decrease from training to validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR WRITTEN RESPONSE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "3. Create a DataFrame consisting of the LinearRegression coefficients along with the feature names, and sort them in decreasing absolute order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "4. Which three features have the highest absolute coefficient values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOUR WRITTEN RESPONSE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### ii. Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Recall that the Lasso model can perform feature selection by shrinking coefficients to 0. For this you will fit a number of models by varying the regularization parameter, and taking note of how many coefficients are set to 0 for each regularization value. Specifically, perform the following:\n",
    "\n",
    "    1. For each alpha in `np.linspace(0, 1, 100)`, do:   \n",
    "    \n",
    "        - Fit a Lasso model with that particular alpha.\n",
    "        - Compute the training and validation MAE. \n",
    "        - Count the number of non-zero coefficients estimated by the model. \n",
    "\n",
    "    2. Create a DataFrame of your results with columns alpha, nbr_non_zero_coeffs, train_mae and valid_mae. Display the first 50 rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "alphas = np.linspace(0, 1, 100)\n",
    "\n",
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "6. Create a line plot with alpha on the x-axis and nbr_non_zero_coeffs on the y-axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "7. After which value of alpha do train_mse and valid_mse no longer change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOUR WRITTEN RESPONSE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "8. Based on your analysis of the 100 models fit in question 5, select an alpha that gives a good trade off between bias and variance, and refit this model on the training data for use in Part III. Name the model you create here `mdl2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE ##### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "9. Recall that in Module 5 calibration curves were discussed. For this question, you will vary the DecisionTreeRegressor's max_depth hyperparameter, and monitor how train MSE and validation MSE vary for each value. \n",
    "\n",
    "\n",
    "    1. For each max_depth in `np.arange(1, 51)`, do:  \n",
    "    \n",
    "        - Fit a DecisionTreeRegressor with that particular max_depth.\n",
    "        - Compute the training and validation MSE. \n",
    "\n",
    "    2. Create a DataFrame of your results with columns max_depth, train_mse, and valid_mse. Display all rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "max_depths = np.arange(1, 51)\n",
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "10. Plot the validation curve comparing train_mse and valid_mse with max_depth on the x-axis. Draw a verical black line at the value of max_depth where overfitting is starting to occur. Be sure to label your axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "11. Based on your analysis of the validation curve in question 10, select a max_depth that gives a good trade off between bias and variance, and refit this model on the training data for use in Part III. Name the model you create here `mdl3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "### iv. Model of Your Choice\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Select a scikit-learn regression model not already covered in this notebook. Select a hyperparameter for that model, and recreate the validation curve created in problem 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "13. Based on your analysis of the validation curve in question 12, select a hyperparameter value that gives a good trade off between bias and variance, and refit this model on the training data for use in Part III. Name the model you create here `mdl4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Part III: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you followed the instructions in terms of naming your models, there should be no coding in this section. Execute the next cell, which computes MSE and MAE on the final test set for the four models created. Recall that:\n",
    "\n",
    "- `mdl1` = Standard LinearRegression model\n",
    "- `mdl2` = Selected Lasso model (after identifying preferred alpha)\n",
    "- `mdl3` = Selected DecisionTreeRegressor (after identifying preferred max_depth)\n",
    "- `mdl4` = Selected model of your choice (after identifying preferred hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run this cell as-is, no updates necessary.\n",
    "\n",
    "ypred_mdl1 = mdl1.predict(dftest)\n",
    "ypred_mdl2 = mdl2.predict(dftest)\n",
    "ypred_mdl3 = mdl3.predict(dftest)\n",
    "ypred_mdl4 = mdl4.predict(dftest)\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    {\n",
    "        \"model\": f\"{repr(mdl1)}\",\n",
    "        \"mse\": mean_squared_error(ypred_mdl1, ytest),\n",
    "        \"mae\": mean_absolute_error(ypred_mdl1, ytest)\n",
    "    },\n",
    "    {\n",
    "        \"model\": f\"{repr(mdl2)}\",\n",
    "        \"mse\": mean_squared_error(ypred_mdl2, ytest),\n",
    "        \"mae\": mean_absolute_error(ypred_mdl2, ytest)\n",
    "    },\n",
    "    {\n",
    "        \"model\": f\"{repr(mdl3)}\",\n",
    "        \"mse\": mean_squared_error(ypred_mdl3, ytest),\n",
    "        \"mae\": mean_absolute_error(ypred_mdl3, ytest)\n",
    "    },\n",
    "    {\n",
    "        \"model\": f\"{repr(mdl4)}\",\n",
    "        \"mse\": mean_squared_error(ypred_mdl4, ytest),\n",
    "        \"mae\": mean_absolute_error(ypred_mdl4, ytest)\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "pd.DataFrame().from_dict(metrics).head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "1. Which model exhibited the best performance in terms of MAE? Which model exhibited the worst performance in terms of MAE? Why do you think the best performing model out-performed the others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOUR WRITTEN RESPONSE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
